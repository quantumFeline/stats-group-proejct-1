\documentclass{article}
%\usepplots_tsv_sync/metrics_by_ntrajmargin=1in]{geometry}
%\usepackage{polski}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{gensymb}
\usepackage{wasysym}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage[makeroom]{cancel}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{multirow}
\usepackage{float}

\title{Statistical Data Analysis 2 - Final Project - Report}
\author{Czapiewska Magdalena, Khodzina Anastasiya, Nechaieva Veronika, Znamierowski Mikołaj}

\begin{document}

\maketitle

\tableofcontents

% You should prepare and submit a comprehensive report describing your experimental setup, the datasets generated, and the results obtained. The report should include the specifications of all Boolean networks considered in your study, along with the corresponding input files containing the simulated datasets provided to BNFinder2. It should justify all methodological choices made and present the results both in written form and through appropriate graphical representations. Finally, the conclusions drawn from your experiments should be clearly articulated.
\vspace{5em}
\noindent
\frame{\large Code is available on GitHub: \href{https://github.com/quantumFeline/stats-group-proejct-1.git}{https://github.com/quantumFeline/stats-group-proejct-1.git}}

\section{Boolean Network representation and construction}

In this section we describe the implementation of the code handling Boolean networks contained in \texttt{BooleanNetwork.py}.
We divide it into four subsections for better readability.

\subsection{Creation of the network}

Each Boolean network is initiated with specified number of nodes, as, according to the project's description, everything else should be randomized.
However, since part II requires the usage of a specific model, we also provide an additional option to specify the transitions (this also gives us a possibility to run more tests on previously created networks, if needed). 
The main usage of this feature is present in loading the networks from files, which will be described later.
If no transitions are specified, the model creates them randomly, with at most $3$ parent nodes for each node. 
The concrete representation of transitions (along with some theoretical issues concerning it) and the method of their creation can be found in the following subsection.

\subsection{Transitions}

Theoretically, each transition has a form of a logical formula (with negations, conjunctions and disjunctions) with nodes as boolean variables. 
However, each such formula can be rewritten in multiple ways, without changing the output. 
For example, the famous De Morgan's law states that $\neg (x_1 \wedge x_2)$ is equivalent to $\neg x_1 \vee \neg x_2$.
To standardize this, the Conjunctive Normal Form (CNF) or the Disjunctive Normal Form (DNF) can be used. 
This however proves quite problematic to implement when creating a random \textbf{unbiased} logical formula (i.e.\ each transition can be achieved with equal probability).
While implementing it, one can also easily run into problems similar to SAT, which are NP-hard.

To address the above issues, the code uses a binary representation of the transitions (in particular, it avoids all logical formulas). 
Namely: each transition is a tuple of two lists.
The first is a list of (non-repeating) parents of length $n$ (where $0 \leq n \leq 3$ is chosen randomly).
The second one is a random binary sequence of length $2^n$.
It represents the transition in the following format: if the last parent is zero, we look at the first half of the sequence, otherwise, on the second half.
We repeat it for all parents (from last to first), reducing our sequence to one element, which is the outcome of the transition. 
This way, all transitions are reachable, and \textbf{equally probable} (for given $n$), thus giving the most general networks.

To illustrate it with an example: suppose that the node $x_2$ has parents $x_3, x_4, x_0$ and the transition is $[0, 1, 0, 1, 1, 0, 1, 1]$.
This means that the transition is described by the following table:

\[
\begin{array}{|ccc|c|}
\hline
x_3 & x_4 & x_0 & x_2 \\
\hline
0 & 0 & 0 & 0 \\
1 & 0 & 0 & 1 \\
0 & 1 & 0 & 0 \\
1 & 1 & 0 & 1 \\
0 & 0 & 1 & 1 \\
1 & 0 & 1 & 0 \\
0 & 1 & 1 & 1 \\
1 & 1 & 1 & 1 \\
\hline
\end{array}
\]

It's worth noting here, that if the node has no parents, by the above implementation, its transition vector has $2^0 = 1$ element. 
However, we don't want to overwrite it with that value, so, when updating the state, its transitions are always skipped (the actual transition applied to it is the identity).

\subsection{Saving and loading the network}

After creating the network, its original structure (i.e. the number of nodes and the transitions) is saved to a file for later reference (which is crucial for the following parts where we compare the ground truth network structure to the BNFinder results).
The format used is the following:
\begin{itemize}
    \item first line of the file is a single integer defining the number of nodes;
    \item each of the next lines defines a transition in the format \verb|[list of node parents]; [transition]| (separated with commas) for the corresponding node.
\end{itemize}
A file with such format can be then loaded into the program, which allows for using custom Boolean networks, not just the random ones.

\subsection{Creating and saving the datasets}

After the creation of our model, we can create datasets by running a single command.
We can specify the following arguments:
\begin{itemize}
    \item \textbf{-d} the number of datapoints (i.e.\ transitions) in the dataset;
    \item \textbf{-l} the length of all trajectories in the dataset;
    \item \textbf{-s} whether the transitions should be applied synchronously or not;
    \item \textbf{-f} the sampling frequency;
\end{itemize}

We randomize the starting states for the trajectories.

Example:
\begin{lstlisting}
    CreateDatasets.py -o output.txt -g network.txt -n 10 -d 20 -l 15 -s
\end{lstlisting}

The datasets created in this way are saved to a file of format compatible with BNFinder2 for later inference.


\section{Attractor detection implementation}

One of the \textbf{key characteristics of a dataset} generated from a Boolean network is the \textbf{proportion of transient and attractor states} present in the observed trajectories.
Since this proportion is explicitly investigated in the project, it is necessary to \textbf{identify attractors in the state space} of each generated network.

To enable control over this characteristic, dedicated classes were implemented that, for a given Boolean network, classify each possible network state either as an attractor state or as a transient state, based on the structure of the state transition graph.

\textbf{The attractor detection strategy depends on the network update mode}, as the structure of the state transition graph differs between synchronous and asynchronous update schemes.
The following subsections describe the approaches used for attractor identification under synchronous and asynchronous dynamics.

\subsection{Attractors in synchronous mode}
The implementation of the \texttt{StateSpaceAnalyzer} class can be found in the \texttt{StateSpaceAnalysisSynchronous.py} file.\newline

For each Boolean network, a \textbf{dictionary} is created that stores \textbf{information for every possible network state}.
Specifically, for each state, it is recorded whether the state \textbf{belongs to an attractor}, the \textbf{identifier of the corresponding attractor}, and the \textbf{distance of the state to the attractor} (with distance 0 for attractor states).\newline

The algorithm uses the fact that \textbf{trajectories in synchronous Boolean networks are deterministic}: the next state of the network is uniquely determined by its current state.
Starting from each state that has not yet been analyzed, the network is iteratively updated following its synchronous dynamics until one of two situations occurs:
\begin{enumerate}
    \item The trajectory reaches a state that \textbf{has already been visited within the current path}. In this case, a \textbf{cycle} (possibly consisting of a single state) has been detected, corresponding to a \textbf{new attractor}. All states in the cycle are marked as attractor states, and transient states leading to the cycle are assigned the corresponding attractor ID along with their distance to the attractor.
    \item The trajectory reaches a state that \textbf{has already been analyzed in a previous trajectory}. In this case, the previously computed attractor information is propagated backward along the current path, assigning attractor IDs and distances to all transient states in the path.
\end{enumerate}

This approach ensures that \textbf{each state in the network is analyzed exactly once}, and that all attractors and their basins of attraction are correctly identified.\newline

The distance from a transient state to its attractor is computed during the analysis. This information was originally intended to support a specific dataset generation strategy, but the approach to dataset generation has since changed. Nevertheless, the class retains the distance computation functionality, as it does not increase the computational cost and could potentially be used in alternative dataset generation strategies.

\subsection{Attractors in asynchronous mode}
Two versions of attractor detection in asynchronous mode were implemented.\newline
The helper class \texttt{AsyncAnalyzer} is provided in the \texttt{AttractorAsynchronous.py} file.\newline
To detect attractors in the state transition graph under asynchronous dynamics, the \texttt{analyze} method can be used either from the \texttt{AsyncAnalyzerNX} class, located in \texttt{AttractorsAsynchronousNetworkx.py}, or from the \texttt{AsyncAnalyzerTarjan} class, located in \texttt{AttractorsAsynchronousTarjan.py}.\newline

In asynchronous state transition system, the next state of the network is \textbf{not uniquely determined} by the current state, because only a single node is updated at a time and the choice of node is random. Consequently, the state transition graph can have multiple outgoing edges from a single state. In this situation, attractors are defined as \textbf{strongly connected components (SCCs) without outgoing edges}, meaning that each state in the component can reach every other state in the component, and no transitions leave the component. Identifying SCCs in the graph allows us to detect all asynchronous attractors and their basins of attraction.\newline

The goal of the analysis is to assign \textbf{to each state of the network} whether it is an attractor or a transient state, and if it is an attractor, to assign the \textbf{identifier of the corresponding attractor}.\newline

The two implemented approaches differ in the method used to find these SCCs:

\begin{enumerate}
    \item \textbf{NetworkX-based approach (\texttt{AsyncAnalyzerNX}):}  
    This approach constructs the full asynchronous state transition graph using the NetworkX library. Strongly connected components are computed with NetworkX's built-in algorithms. SCCs that have no outgoing edges are identified as attractors, and all other states are marked as transient. Each attractor state is assigned an attractor ID.

    \item \textbf{Tarjan-based approach (\texttt{AsyncAnalyzerTarjan}):}  
    This approach implements \textbf{Tarjan's algorithm} for finding strongly connected components directly, without relying on external libraries. Each SCC is checked for outgoing edges, and those without outgoing edges are classified as attractors. Transient states are marked accordingly. Each attractor state is assigned an attractor ID.
\end{enumerate}

In this project, we use the \texttt{AsyncAnalyzerNX} class. Since the NetworkX library was introduced during the course, we consider its use appropriate for this analysis.

\section{Datasets generation}

\subsection{The way of generating a dataset with given characteristics}

The dataset generation process is implemented in \texttt{GenerateTrajectories.py}. For each network size $n$ in the range from 5 to 16, a Boolean network is created. For each network and for each update mode (synchronous or asynchronous), the following tasks are performed:

\begin{enumerate}
    \item \textbf{State space analysis:} The full state space of the Boolean network is analyzed to identify attractor and transient states. In synchronous mode, the \texttt{StateSpaceAnalyzer} class is used, while in asynchronous mode, the \texttt{AsyncAnalyzerNX} class is employed.

    \item \textbf{Long trajectories generation:} From every possible initial state of the network, a long trajectory of states is generated by iteratively applying the network update rules. In total, $2^n$ trajectories of length 300 are generated, providing a base from which shorter dataset fragments can later be sampled.

    \item \textbf{Loop:} For each combination of dataset parameters (number of trajectories, trajectory length, sampling frequency and transient fraction) the sampling process is applied to create dataset fragments with the requested characteristics.
    \begin{itemize}

    \item \textbf{Fragment candidate identification:} For each long trajectory, multiple candidate fragments are considered by varying the starting offset (from 0 to \texttt{sampling\_frequency}-1) and applying the user-defined sampling frequency. Each candidate fragment is checked to ensure it contains at least the required number of transient states and attractor states according to the desired fraction. Only fragments meeting these criteria are retained as candidates.

    \item \textbf{Fragment shuffling, trimming, and uniqueness check:} Candidate fragments are first randomly shuffled. Then, for each candidate, if the dataset has not yet reached the desired number of trajectories, a fragment is selected by taking every \texttt{sampling\_frequency}-th state and deterministically picking the last required transient states and the first required attractor states. This ensures that each fragment has the desired length and maintains the intended proportion of transient to attractor states. After trimming, each fragment is represented as a tuple and checked against already selected fragments. If the fragment is already included, it is skipped. This process guarantees that all trajectories in the final dataset are distinct and that the dataset contains the requested number of trajectories.

    \item \textbf{Insufficient candidate handling:} If at any stage there are not enough fragments to satisfy the requested number of trajectories - either because the number of candidate fragments before trimming is too small, or because there are not enough unique fragments after trimming - the sampling function returns \texttt{None}. This guarantees that no dataset is created with fewer trajectories than requested.
    \end{itemize}
\end{enumerate}

\subsection{Description of the datasets generated}

\begin{itemize}
    \item \textbf{Network size ($n$):} The number of nodes in the Boolean network, ranging from 5 to 16. For each $n$, a separate Boolean network is created.
    \item \textbf{Number of data points:} 13 values ranging from 3 to 39 (step size of 3).
    \item \textbf{Trajectory length:} 13 values ranging from 3 to 39 (step size of 3).
    \item \textbf{Update mode:} Synchronous and Asynchronous.
    \item \textbf{Sampling frequency:} 1, 2, and 3.
    \item \textbf{Fraction of transient states:} 0.2, 0.4, 0.6, 0.8.
\end{itemize}

In some cases, it was not possible to generate a dataset with the requested characteristics. This typically occurred for small networks (small $n$) and synchronous update mode, where the combination of a long required trajectory length and a high transient fraction made it impossible to find enough trajectory fragments that satisfied the criteria. In such cases, the dataset generation function returned \texttt{None} and no dataset was created for that parameter combination.\newline\newline

\section{BNFinder2 usage}

BNFinder2 was used to reconstruct networks from generated datasets (trajectories). Since the tool relies on the deprecated Python 2.7 and specific libraries (Scipy, FPConst), an isolated Conda environment was established to resolve dependency conflicts.\newline\newline

The execution of BNFinder2 on datasets derived from synthetic networks is implemented in the \texttt{RunBnfExperiments.py} script.\newline\newline

Due to a long computation time, we needed to reduce the number of parameters in a grid for bigger number of nodes.\newline\newline
For $n = 5..13$ we run bnf for the parameters:
\begin{itemize}
    \item \textbf{Number of data points:} 13 values ranging from 3 to 39 (step size of 3).
    \item \textbf{Trajectory length:} 13 values ranging from 3 to 39 (step size of 3).
    \item \textbf{Update mode:} Synchronous and Asynchronous.
    \item \textbf{Sampling frequency:} 1, 2, and 3.
    \item \textbf{Fraction of transient states:} 0.2, 0.4, 0.6, 0.8.
\end{itemize}
\vspace{0.5em}
For $n = 14..16$ we run bnf for the parameters:
\begin{itemize}
    \item \textbf{Number of data points:} 3, 15, 27, 39.
    \item \textbf{Trajectory length:} 3, 15, 27, 39.
    \item \textbf{Update mode:} Synchronous and Asynchronous.
    \item \textbf{Sampling frequency:} 1, 2, and 3.
    \item \textbf{Fraction of transient states:} 0.2, 0.6.
\end{itemize}
\noindent
In the script we leave the version for reconstructing networks from all datasets.

\section{Evaluation of the accuracy of the reconstructed network}

\subsection{Evaluation metrics chosen}

Boolean networks are directed graphs. To compute evaluation metrics, we represent the networks using adjacency matrices, where 
$A[i, j] = 1$ if and only if there is a directed edge from $x_i$ to $x_j$, and $A[i, j] = 0$ otherwise.\newline\newline
The accuracy of the reconstructed networks is assessed using five measures: recall, precision, F1-score, normalized Hamming distance and normalized Structural Hamming distance. Ideally, recall, precision, and F1-score should be high, whereas the normalized Hamming and Structural Hamming distances should be low.\newline\newline
All functions for computing metrics from adjacency matrices, as well as for generating adjacency matrices from ground truth files or SIF files (outputs of BNFinder), are implemented in the file \texttt{EvaluationMetrics.py}.\newline
The evaluation of BNFinder results on datasets generated from synthetic networks is implemented in \texttt{EvaluateAllBnfResults.py}.\newline\newline

{\large \textbf{Description of metrics and justification of choice}}\newline\newline
\noindent
We define the basic quantities as follows:

\begin{itemize}
    \item $\mathrm{TP}$ (true positives) -- the number of edges present in both the ground truth network and the reconstructed network
    \item $\mathrm{FP}$ (false positives) -- the number of edges present in the reconstructed network but absent in the ground truth network
    \item $\mathrm{TN}$ (true negatives) -- the number of ordered pairs of nodes without an edge in both the ground truth and reconstructed networks
    \item $\mathrm{FN}$ (false negatives) -- the number of edges present in the ground truth network but missing in the reconstructed network
\end{itemize}
\noindent
\fbox{\textbf{Recall}}
\[
\mathrm{Recall} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FN}}
\]
Recall allows measuring the fraction of dependencies (edges) present in the ground truth network that are also identified in the reconstructed network.\newline\newline
\noindent
\fbox{\textbf{Precision}}
\[
\mathrm{Precision} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}}
\]
Precision allows quantifying the proportion of edges inferred by the algorithm that are indeed present in the ground truth network.\newline\newline
\noindent
\fbox{\textbf{F1-score}}
\[
\mathrm{F1} = 2 \cdot \frac{\mathrm{Precision} \cdot \mathrm{Recall}}
{\mathrm{Precision} + \mathrm{Recall}}
\]
The F1-score is the harmonic mean of precision and recall. It reaches high values only if both precision and recall are high, making it a good indicator of the quality of the reconstruction, as it measures both whether the algorithm correctly reconstructed the edges that exist and whether it avoided reconstructing edges that should not be present.\newline\newline
\noindent
\fbox{\textbf{Hamming distance}}\newline\newline
\noindent
The Hamming distance counts the total number of differing entries between  the adjacency matrices of the ground truth and reconstructed networks:
\[
\mathrm{HD} = \sum_{i,j} \mathbf{1}[A[i,j] \neq B[i,j]],
\]
where $A$ and $B$ are the adjacency matrices.\newline\newline
To compare the reconstruction accuracy across networks of different sizes, we define the normalized Hamming distance by dividing the Hamming distance by the total number of ordered pairs of vertices:
\[
\mathrm{HD}_{\mathrm{norm}} = \frac{\mathrm{HD}}{n^2},
\]
where $n$ is the number of nodes in the network.\newline\newline
The normalized Hamming distance allows measuring the fraction of ordered pairs of vertices $(i, j)$ for which either a directed edge from $i$ to $j$ exists in the ground truth but is missing in the reconstruction, or the edge is inferred by the reconstruction but does not exist in the ground truth.\newline\newline
\noindent
\fbox{\textbf{Structural Hamming distance}}\newline\newline
\noindent
The Structural Hamming distance (SHD) measures the number of unordered pairs of vertices for which the interactions in the reconstructed network need to be modified to match the ground truth network.
Each inconsistency between a pair of vertices - whether it requires an edge addition, removal, or reversal - counts as one operation.
In other words, we count whether a pair is incorrect, without distinguishing the type of correction needed (and without counting the number of corrections - addition of 2 edges counts as 1).\newline\newline
Consider a pair of vertices $(i, j)$:
\begin{itemize}
\item{For self-loops ($i = j$), a mismatch between the ground truth and reconstructed network counts as one operation.}
\item{Now consider $i \neq j$. Let $(p, q)$ denote the edge configuration in the network, where $p = 1$ if there is an edge $i \to j$ (otherwise $p = 0$) and $q = 1$ if there is an edge $j \to i$ (otherwise $q = 0$). The following table summarizes the SHD contribution for each possible combination of ground truth and reconstructed configurations:}
\end{itemize}
\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{2}{*}{Ground truth $(p,q)$} & \multicolumn{4}{c|}{Reconstructed $(p,q)$} \\
\cline{2-5}
 & (0,0) & (1,0) & (0,1) & (1,1) \\ 
\hline
(0,0) & 0 & 1 (remove $i\to j$) & 1 (remove $j\to i$) & 1 (remove both edges) \\ 
\hline
(1,0) & 1 (add $i\to j$) & 0 & 1 (reverse $j\to i$) & 1 (remove $j\to i$) \\ 
\hline
(0,1) & 1 (add $j\to i$) & 1 (reverse $i\to j$) & 0 & 1 (remove $i\to j$) \\ 
\hline
(1,1) & 1 (remove both edges) & 1 (add $j\to i$) & 1 (add $i\to j$) & 0 \\ 
\hline
\end{tabular}
\end{table}
\noindent
To compare reconstruction accuracy across networks of different sizes, we define the normalized Structural Hamming distance by dividing the Structural Hamming distance by the total number of unordered pairs of vertices, including self-loops:
\[
\mathrm{SHD}_{\mathrm{norm}} = \frac{\mathrm{SHD}}{\frac{n(n-1)}{2} + n},
\]
where $n$ is the number of vertices in the network.\newline\newline
The normalized Structural Hamming distance measures the fraction of unordered pairs of vertices $(i, j)$ for which the interaction in the reconstructed network differs from the interaction in the ground truth network.

\subsection{Results}

We used a custom Python script (\texttt{RunBnfExperiments.py}) to fully automate the reconstruction process and evaluation.
The script iterates over all combinations of parameters considered (see the list in BNFinder2 usage) and saves results. Then a script \texttt{EvaluateAllBnfResults.py} is used to collect the metrics measuring the Bayesian network restoration for each combination.
The results are stored in a .tsv table (\texttt{tables/evaluation\_asynchronous.tsv}, \texttt{tables/evaluation\_synchronous.tsv}).

After the .tsv results are created, a separate script - \texttt{NetworkAccuracyEvaluation.py} goes over the results and displays the aggregated, averaged-out metrics depending on the given parameters.
The following graph types were used:

\begin{itemize}
    \item Linear graph (metric against a parameter)
    \item Linear comparison graph (MDL vs BDE evaluation)
    \item Heatmap (metric against a pair of parameters)
    \item Bar plot (a collection different metrics against a parameter)
\end{itemize}

For most graphs presented we use aggregated metric, i.e.\ we consider all possible values of the parameters not analyzed in the given graph; we also created some graphs where the other parameters are fixed.
In theory, this should be able to pick up on stronger correlation, as in situations where other parameters are suboptimal (e.g.\ good trajectory length but too few data points or vice versa) there is more noise, which may make the positive trends less apparent.
In practice, this results in having too little overall data to average out and, consequentially, too much noise.
However, the plots from synchronous and asynchronous data were nevertheless separated for this section.

%We start with comparing the results for different metrics, depending on the number of trajectories (a strictly positive parameters - just more data with no downsides), in order to choose which metric to focus on.

We begin the analysis by presenting a complete overview of all evaluation metrics for both update modes.
For each mode (synchronous and asynchronous), we show grouped bar plots comparing all computed accuracy metrics
(Hamming distance fraction, Structural Hamming distance fraction, precision, recall, and F1 score)
as a function of key experimental parameters.

\subsubsection*{Synchronous update mode}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_sync/metrics_by_ntraj}
    \caption{Comparison of all accuracy metrics as a function of the number of trajectories (synchronous mode).}
    \label{fig:sync_metrics_ntraj}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv/metrics_by_len}
    \caption{Comparison of all accuracy metrics as a function of trajectory length (synchronous mode).}
    \label{fig:sync_metrics_len}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_sync/metrics_by_nodes}
    \caption{Comparison of all accuracy metrics as a function of network size (synchronous mode).}
    \label{fig:sync_metrics_nodes}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv/metrics_by_tf}
    \caption{Comparison of all accuracy metrics as a function of transient fraction (synchronous mode).}
    \label{fig:sync_metrics_tf}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv/metrics_by_sf}
    \caption{Comparison of all accuracy metrics as a function of sampling frequency (synchronous mode).}
    \label{fig:sync_metrics_sf}
\end{figure}

\subsubsection*{Asynchronous update mode}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_async/metrics_by_ntraj}
    \caption{Comparison of all accuracy metrics as a function of the number of trajectories (asynchronous mode).}
    \label{fig:async_metrics_ntraj}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_async/metrics_by_len}
    \caption{Comparison of all accuracy metrics as a function of trajectory length (asynchronous mode).}
    \label{fig:async_metrics_len}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_async/metrics_by_nodes}
    \caption{Comparison of all accuracy metrics as a function of network size (asynchronous mode).}
    \label{fig:async_metrics_nodes}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_async/metrics_by_tf}
    \caption{Comparison of all accuracy metrics as a function of transient fraction (asynchronous mode).}
    \label{fig:async_metrics_tf}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_async/metrics_by_sf}
    \caption{Comparison of all accuracy metrics as a function of sampling frequency (asynchronous mode).}
    \label{fig:async_metrics_sf}
\end{figure}

From these graphs we can see that the F1 is the most responsive metric.
Specifically, the change in F1 tracks the performance change most clearly in the sanity-check cases, such as increased data volume.
Therefore, for the next graphs we will focus on it as our primary metric.

In the follow graphs we can observe that both increasing trajectory length and the number of trajectories improves the algorithm performance; however, increasing trajectory length has diminishing returns, capping at around 20.
This is most likely because by this point the trajectory reached the attractor state, and cycling through it further does not provide any additional information.

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_sync/f1_vs_len}
    \label{fig:F1 depending on trajectory length}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_sync/f1_vs_ntraj}
    \label{fig:F1 depending on dataset size}
\end{figure}

The graph size does not have significant effect on performance either way - it is more data to analyze but also a more complicated network structure to derive.

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_sync/f1_vs_nodes}
    \label{fig:F1 depending on graph size}
\end{figure}

When plotting against both trajectory length and dataset size, there is no significant correlation between the two - they both contribute positively to the result independently.

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_sync/heatmap_f1_ntraj_len}
    \label{fig:F1 depending on trajectory length and number of trajectories}
\end{figure}

The asynchronous datasets results are similar.
The main difference we can notice is that the trajectory length caps out more gradually - likely because for a given trajectory it is not guaranteed when the next step will get picked up.
The correlations are also more clearly observes, likely due to large total data volume as synchronous dataset omits some parameter combinations that are possible when in asynchronous mode.


\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_async/f1_vs_len}
    \label{fig:F1 depending on trajectory length (async)}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_async/f1_vs_ntraj}
    \label{fig:F1 depending on dataset size (async)}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_async/f1_vs_nodes}
    \label{fig:F1 depending on graph size (async)}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_async/heatmap_f1_ntraj_len}
    \label{fig:F1 depending on trajectory length and number of trajectories (async)}
\end{figure}

As for the scoring method, we can see that while the performance is generally comparable, MDL stably gives slightly better results than BDE.
There are no significant gaps in performance that would clearly favour one method over enough - MDL is just stably slightly better across the board.

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_sync/f1_vs_nodes_by_score}
    \label{fig:MDL vs BDE}
\end{figure}.png

Similar picture can be observed for asynchronous graphs, with advantage somewhat more apparent.

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_tsv_async/f1_vs_nodes_by_score}
    \label{fig:MDL vs BDE (async)}
\end{figure}.png

In the next part we therefore choose MDL as our only scoring method.

\section{Reconstructing the model of a real-life biological mechanism}
\subsection{Chosen Model}
\textbf{MIR-9-NEUROGENESIS} (\textbf{ID = 88})  Boolean Network model was chosen from Biodivine repository, because it has small number of nodes(6), which reduces computational complexity and should give better accuracy, and has zero inputs, which eliminates the need to simulate external environmental changes, allowing for a straightforward simulation of the network's internal dynamics. Below you can see graph for MIR9 model where yellow nodes are attractors.
\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{Figure_model_MIR9.png}
    \label{fig:MIR9}
\end{figure}

Variables: $V = \{x_0, x_1, x_2, x_3, x_4, x_5\}$

Predictor functions: $f_0(x_2) = x_2$

$f_1(x_3, x_5) = (\neg x_3 \land x_5) \lor x_3$  (equivalent to $x_3 \lor x_5$)

$f_2(x_1, x_4) = \neg x_4 \land \neg x_1$

$f_3(x_0, x_4) = \neg x_4 \land \neg x_0$

$f_4(x_0, x_3) = \neg x_3 \land \neg x_0$

$f_5(x_0, x_4) = \neg x_4 \land \neg x_0$

\subsection{Datasets Generation}
A total of 1014 datasets were generated using BooleanNetwork class method create\_dataset from \texttt{BooleanNetwork.py} to assess the algorithm's robustness. The datasets covered a combination of the following parameters:
\begin{itemize}
    \item \textbf{Number of data points:} 13 values ranging from 3 to 39 (step size of 3).
    \item \textbf{Trajectory length:} 13 values ranging from 3 to 39.
    \item \textbf{Update mode:} Synchronous and Asynchronous.
    \item \textbf{Sampling frequency:} 1, 2, and 3.
    \item \textbf{Initialization:} Random starting state for all simulations.
\end{itemize}
The total number of combinations is calculated as $13 \times 13 \times 2 \times 3 = 1014$ datasets.

\subsection{Reconstructing}
The next step was to reconstruct Bayesian Network with MDL scoring function, which was chosen based on the insights from the first Part.
This allowed for the batch processing of all 1014 datasets and the automatic calculation of all metrics defined in Part 1.

The evaluation process was analogous to evaluation in part 1.
While some technical modifications were needed in order to account for a different data format (.csv file, column names, number formatting), the general approach was the same for both evaluations, and the script could be easily extended.
A function was added to compare the results on sync and async datasets.

\subsection{Results}

The results on MIR9 dataset are less clear in comparison to artificial data.
However, some positive correlation with the dataset size can be nevertheless observed:

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_mir9/sync_async_datapoints}
    \label{fig:F1 against datapoints; sync and async}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=13cm]{plots_mir9/sync_async_length}
    \label{fig:F1 against trajectory length; sync and async}
\end{figure}

This is likely due to the real-life being noisier.

\section{Contributions}

Authors (given in alphabetical order) and their contributions to the project:
\begin{itemize}
    \item Czapiewska Magdalena:
    \begin{itemize}
    \item Implementing attractor detection in the state space for synchronous update mode
    \item Implementing attractor detection in the state space for asynchronous update mode (two approaches)
    \item Implementing functions for generating datasets, taking into account update mode, number of data points, trajectory length, sampling frequency and fraction of transient states
    \item Implementing a script for generating datasets for synthetic networks
    \item Implementing a script to run BNFinder2 on datasets derived from synthetic networks
    \item Choosing, describing and implementing evaluation metrics
    \item Creating a script for evaluating BNFinder2 results
    \item Report: Attractor detection implementation (2), Datasets generation (3), Evaluation of the accuracy of the reconstructed network (only description of the metrics in 5.1, without results in 5.2)
\end{itemize}
    \item Khodina Anastasiya(whole Part 2):
    \begin{itemize}
        \item Choosing the appropriate model in Part 2
        \item Interpreting/Processing chosen model code
        \item Creating inference of BN class for the model
        \item Generating trajectories for the model
        \item Reconstructing the BN from created trajectories
        \item Calculating metrics for the model reconstruction from Part 2
        \item Creating graphical representation for the model\
        \item Describing Part 2 in the report (6.1, 6.2, 6.3, without results in 6.4)
    \end{itemize}
    \item Nechaieva Veronika:
    \begin{itemize}
        \item Organisational activity (Github etc.)
        \item Reworking the code for Boolean networks; readability
        \item Saving and loading the network ground truth structure
        \item Implementing the dataset save/load in a proper format for BNFinder2
        \item Converting the Python scripts to work with command-line arguments
        \item Testing BNF base functionality
        \item Processing and converting of the aggregated BNFinder results
        \item Implementing the graphs plotting (single-argument plots, heatmaps, metrics comparison)
        \item Evaluating the network-finding accuracy according to the implemented metrics
        \item Report: result analysis (for subcases as well as the general cases) for Part 1 (5.2) and Part 2 (6.4).
        \item Editing and reviewing
    \end{itemize}
    \item Znamierowski Mikołaj:
    \begin{itemize}
        \item Gathering the group and initiating the work.
        \item Finding and sharing crucial resources regarding BNFinder2.
        \item Implementing the main code for Boolean network class: setting proper structure, functionalities, transitions, etc.
        \item Implementing functions that create the datasets and save them in a file.
        \item Explaining to the rest of the group how to use the code.
        \item Describing the most important parts of the above implementations in the report (i.e. writing the first section).
    \end{itemize}
\end{itemize}

\end{document}
